{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1RFbhYViOkxrtLamGJI5RS33E6Rw-xivU",
   "authorship_tag": "ABX9TyNTogB+y7qDh3YiBcACWJw4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# install pytorch_tabnet\n"
   ],
   "metadata": {
    "id": "r33srRLWZR3_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pytorch_tabnet"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhlOixNTYHqh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706803359818,
     "user_tz": -60,
     "elapsed": 13763,
     "user": {
      "displayName": "Zhiguang Li",
      "userId": "06031394133879865151"
     }
    },
    "outputId": "a5f06080-1b4b-4bec-f2c2-eece9807fcc0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pytorch_tabnet\n",
      "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/44.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.5/44.5 kB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.23.5)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.2.2)\n",
      "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.1.0+cu121)\n",
      "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.66.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
      "Installing collected packages: pytorch_tabnet\n",
      "Successfully installed pytorch_tabnet-4.1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import\n"
   ],
   "metadata": {
    "id": "4wRkKioaZdu1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFaS3JqxjsT0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def fix_random(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "fix_random(42)\n",
    "\n",
    "apply_pca = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "CRBMDS_Eju3_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# read dataset"
   ],
   "metadata": {
    "id": "ZzVfCWA5Zhgw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#import dataset\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive') #connect the drive\n",
    "dataset_file = '/content/drive/MyDrive/W-Workspace/MovieLens_da_li/dataset'\n",
    "df = pd.read_csv(dataset_file + '/dataset.csv')"
   ],
   "metadata": {
    "id": "sp9cuZFmjyOr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706803507417,
     "user_tz": -60,
     "elapsed": 16444,
     "user": {
      "displayName": "Zhiguang Li",
      "userId": "06031394133879865151"
     }
    },
    "outputId": "d69ffeea-6428-4110-ef4e-80badd4adb12"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n"
   ],
   "metadata": {
    "id": "ubaSOQl4Zmcp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 分割数据集为特征和目标\n",
    "X = df.drop(['rating'], axis=1).to_numpy()  # 移除'rating'列，其余作为特征\n",
    "y = df['rating'].to_numpy()  # 'rating'列作为目标\n",
    "\n",
    "# 分割数据集为训练+验证集和测试集（测试集20%）\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# 分割训练+验证集为训练集和验证集（验证集占前者的10%）\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "# 将目标变量重塑为列向量以符合某些模型的要求\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "# 打印各数据集的样本数量以确认分割正确\n",
    "print(\"Number of train set: \", X_train.shape[0])\n",
    "print(\"Number of test set: \", X_test.shape[0])\n",
    "print(\"Number of validation set: \", X_val.shape[0])\n",
    "\n"
   ],
   "metadata": {
    "id": "N0_6ZNzrj1nU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706803508690,
     "user_tz": -60,
     "elapsed": 417,
     "user": {
      "displayName": "Zhiguang Li",
      "userId": "06031394133879865151"
     }
    },
    "outputId": "61901d49-2837-4ca7-dc1c-7b98bdecd309"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of train set:  9946\n",
      "Number of test set:  2764\n",
      "Number of validation set:  1106\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 检查是否应用PCA进行维度缩减\n",
    "if apply_pca:\n",
    "    pca = PCA(n_components=0.95)\n",
    "    # 对训练数据拟合PCA同时转换训练数据\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    # 仅转换验证集和测试集\n",
    "    X_val = pca.transform(X_val)\n",
    "    X_test = pca.transform(X_test)\n",
    "else:\n",
    "    print(\"PCA is not applied\")"
   ],
   "metadata": {
    "id": "uJMR5FnZj37s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "\n",
    "# 定义超参数范围\n",
    "\n",
    "batch_sizes = [256]   # 批量大小保持不变\n",
    "n_epochs = [200]      # 训练周期数保持不变\n",
    "n_d = [16]            # 仅选择一个预测层维度 初始状态 n_d = [8, 16, 32]  # 预测层的维度\n",
    "n_a = [16]            # 仅选择一个注意力层维度 初始状态 n_a = [8, 16, 32]  # 注意力层的维度\n",
    "n_steps = [3, 5]      # 减少网络中连续步骤的数量选项 初始状态 n_steps = [3, 5, 7]  # 网络中连续步骤的数量\n",
    "n_indipendent = [2]   # 仅选择一个独立GLU层的数量选项 初始状态 n_indipendent = [2, 3]  # 每个GLU块中独立GLU层的数量\n",
    "\n",
    "# 生成所有可能的参数组合\n",
    "params = list(product(batch_sizes, n_epochs, n_d, n_a, n_steps, n_indipendent))\n",
    "\n",
    "# 直接计算组合数量\n",
    "print(\"Number of combinations: \", len(params))"
   ],
   "metadata": {
    "id": "UPFbkgAdj63i",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706803515312,
     "user_tz": -60,
     "elapsed": 13,
     "user": {
      "displayName": "Zhiguang Li",
      "userId": "06031394133879865151"
     }
    },
    "outputId": "caf6671e-9d60-454d-eec8-feb201ee3831"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of combinations:  2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model(n_d, n_a, n_steps, n_independent):\n",
    "    \"\"\"\n",
    "    创建并返回一个配置了特定超参数的TabNetRegressor模型实例。\n",
    "\n",
    "    Parameters:\n",
    "    - n_d: 预测层的维度。\n",
    "    - n_a: 注意力层的维度。\n",
    "    - n_steps: 模型的步数。\n",
    "    - n_independent: 独立GLU层的数量。\n",
    "\n",
    "    Returns:\n",
    "    - TabNetRegressor模型实例。\n",
    "    \"\"\"\n",
    "    model = TabNetRegressor(\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        n_independent=n_independent  # 确保参数名称正确\n",
    "    )\n",
    "    return model"
   ],
   "metadata": {
    "id": "vK4e1EHyj8rv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "best_params = None\n",
    "iteration = 0\n",
    "\n",
    "for b, n_e, n_d, n_a, n_s, n_i in params:\n",
    "    iteration += 1\n",
    "    print(f'\\nIteration {iteration}/{len(params) }')\n",
    "    print(f\"Configuration: batch size = {b}, epochs = {n_e}, n_d = {n_d}, n_a = {n_a}, steps = {n_s}, n_independent = {n_i}\")\n",
    "\n",
    "    model = get_model(n_d, n_a, n_s, n_i)  # 修正调用\n",
    "    base_path = \"/content/drive/MyDrive/W-Workspace/MovieLens_da_li/results/TabNet\"\n",
    "    sub_dir = \"pca\" if apply_pca else \"no_pca\"\n",
    "    log_dir = os.path.join(base_path, sub_dir, f\"batch_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndependent_{n_i}\")\n",
    "\n",
    "\n",
    "    if os.path.exists(log_dir):\n",
    "        print(\"Model already trained. Skipping...\")\n",
    "        continue\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    # 确保目录存在（如果需要的话）\n",
    "    os.makedirs(os.path.dirname(log_dir), exist_ok=True)\n",
    "\n",
    "    #fit model\n",
    "    model.fit(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_name=['mse'],\n",
    "        patience=10,\n",
    "        batch_size=b,\n",
    "        virtual_batch_size=128\n",
    "    )\n",
    "\n",
    "    # evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "   #save hparams for each iteration with tensorboard\n",
    "    writer.add_hparams(\n",
    "        {'batch_size': b, 'n_epochs': n_e, 'n_d': n_d, 'n_a': n_a, 'n_steps': n_s, 'n_indipendent': n_i},\n",
    "        {'hparam/mse': mse, 'hparam/r2': r2}\n",
    "    )\n",
    "    print('MSE:', mse)\n",
    "    print('R2 Score:', r2)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_params = (b, n_e, n_d, n_a, n_s, n_i)\n",
    "        print('Best model updated')\n",
    "    writer.close()\n",
    "# 注：模型训练和评估部分省略了详细的fit和predict调用以及TensorBoard日志记录，因为它们已经正确无误。"
   ],
   "metadata": {
    "id": "RHMXMX2Mj-TS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "faf67e45-9666-43e5-a92a-a67a71ded1cf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706804299979,
     "user_tz": -60,
     "elapsed": 783893,
     "user": {
      "displayName": "Zhiguang Li",
      "userId": "06031394133879865151"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Iteration 1/2\n",
      "Configuration: batch size = 256, epochs = 200, n_d = 16, n_a = 16, steps = 3, n_independent = 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0  | loss: 1.86584 | mse_mse: 0.63007 |  0:00:04s\n",
      "epoch 1  | loss: 0.30308 | mse_mse: 0.31684 |  0:00:08s\n",
      "epoch 2  | loss: 0.24654 | mse_mse: 0.26662 |  0:00:18s\n",
      "epoch 3  | loss: 0.2296  | mse_mse: 0.21074 |  0:00:28s\n",
      "epoch 4  | loss: 0.2268  | mse_mse: 0.19321 |  0:00:33s\n",
      "epoch 5  | loss: 0.21625 | mse_mse: 0.19237 |  0:00:37s\n",
      "epoch 6  | loss: 0.20631 | mse_mse: 0.19008 |  0:00:42s\n",
      "epoch 7  | loss: 0.2003  | mse_mse: 0.19423 |  0:00:46s\n",
      "epoch 8  | loss: 0.18557 | mse_mse: 0.14818 |  0:00:51s\n",
      "epoch 9  | loss: 0.16535 | mse_mse: 0.14568 |  0:00:56s\n",
      "epoch 10 | loss: 0.13521 | mse_mse: 0.08652 |  0:01:00s\n",
      "epoch 11 | loss: 0.10368 | mse_mse: 0.08014 |  0:01:05s\n",
      "epoch 12 | loss: 0.08161 | mse_mse: 0.06133 |  0:01:10s\n",
      "epoch 13 | loss: 0.06801 | mse_mse: 0.05045 |  0:01:14s\n",
      "epoch 14 | loss: 0.05899 | mse_mse: 0.04497 |  0:01:18s\n",
      "epoch 15 | loss: 0.05507 | mse_mse: 0.04635 |  0:01:23s\n",
      "epoch 16 | loss: 0.04928 | mse_mse: 0.0393  |  0:01:27s\n",
      "epoch 17 | loss: 0.0417  | mse_mse: 0.03102 |  0:01:32s\n",
      "epoch 18 | loss: 0.03432 | mse_mse: 0.02925 |  0:01:37s\n",
      "epoch 19 | loss: 0.03087 | mse_mse: 0.02845 |  0:01:41s\n",
      "epoch 20 | loss: 0.0335  | mse_mse: 0.02019 |  0:01:45s\n",
      "epoch 21 | loss: 0.02699 | mse_mse: 0.01885 |  0:01:51s\n",
      "epoch 22 | loss: 0.02376 | mse_mse: 0.0164  |  0:01:55s\n",
      "epoch 23 | loss: 0.02276 | mse_mse: 0.0171  |  0:01:59s\n",
      "epoch 24 | loss: 0.02179 | mse_mse: 0.01582 |  0:02:05s\n",
      "epoch 25 | loss: 0.01691 | mse_mse: 0.01396 |  0:02:10s\n",
      "epoch 26 | loss: 0.01894 | mse_mse: 0.01572 |  0:02:15s\n",
      "epoch 27 | loss: 0.01646 | mse_mse: 0.01212 |  0:02:20s\n",
      "epoch 28 | loss: 0.01663 | mse_mse: 0.01244 |  0:02:24s\n",
      "epoch 29 | loss: 0.01738 | mse_mse: 0.01378 |  0:02:29s\n",
      "epoch 30 | loss: 0.01602 | mse_mse: 0.01102 |  0:02:34s\n",
      "epoch 31 | loss: 0.01587 | mse_mse: 0.0129  |  0:02:38s\n",
      "epoch 32 | loss: 0.01537 | mse_mse: 0.01564 |  0:02:44s\n",
      "epoch 33 | loss: 0.01633 | mse_mse: 0.01294 |  0:02:48s\n",
      "epoch 34 | loss: 0.01994 | mse_mse: 0.01216 |  0:02:53s\n",
      "epoch 35 | loss: 0.01406 | mse_mse: 0.01062 |  0:02:58s\n",
      "epoch 36 | loss: 0.01545 | mse_mse: 0.00958 |  0:03:02s\n",
      "epoch 37 | loss: 0.01226 | mse_mse: 0.01083 |  0:03:07s\n",
      "epoch 38 | loss: 0.01326 | mse_mse: 0.01001 |  0:03:12s\n",
      "epoch 39 | loss: 0.01167 | mse_mse: 0.01056 |  0:03:16s\n",
      "epoch 40 | loss: 0.01208 | mse_mse: 0.0141  |  0:03:20s\n",
      "epoch 41 | loss: 0.0114  | mse_mse: 0.00823 |  0:03:26s\n",
      "epoch 42 | loss: 0.01245 | mse_mse: 0.01011 |  0:03:30s\n",
      "epoch 43 | loss: 0.01384 | mse_mse: 0.00965 |  0:03:34s\n",
      "epoch 44 | loss: 0.01333 | mse_mse: 0.01128 |  0:03:40s\n",
      "epoch 45 | loss: 0.01233 | mse_mse: 0.01555 |  0:03:44s\n",
      "epoch 46 | loss: 0.0138  | mse_mse: 0.01146 |  0:03:48s\n",
      "epoch 47 | loss: 0.01314 | mse_mse: 0.00824 |  0:03:54s\n",
      "epoch 48 | loss: 0.01239 | mse_mse: 0.01191 |  0:03:58s\n",
      "epoch 49 | loss: 0.01091 | mse_mse: 0.01151 |  0:04:02s\n",
      "epoch 50 | loss: 0.01    | mse_mse: 0.00744 |  0:04:08s\n",
      "epoch 51 | loss: 0.01076 | mse_mse: 0.00992 |  0:04:12s\n",
      "epoch 52 | loss: 0.01267 | mse_mse: 0.01206 |  0:04:16s\n",
      "epoch 53 | loss: 0.00955 | mse_mse: 0.01127 |  0:04:22s\n",
      "epoch 54 | loss: 0.01367 | mse_mse: 0.01453 |  0:04:26s\n",
      "epoch 55 | loss: 0.01653 | mse_mse: 0.01811 |  0:04:30s\n",
      "epoch 56 | loss: 0.01321 | mse_mse: 0.00965 |  0:04:35s\n",
      "epoch 57 | loss: 0.01036 | mse_mse: 0.0081  |  0:04:40s\n",
      "epoch 58 | loss: 0.01208 | mse_mse: 0.01046 |  0:04:44s\n",
      "epoch 59 | loss: 0.01182 | mse_mse: 0.00757 |  0:04:49s\n",
      "epoch 60 | loss: 0.01043 | mse_mse: 0.01071 |  0:04:54s\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_mse_mse = 0.00744\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE: 0.007878176810709618\n",
      "R2 Score: 0.9644592608757693\n",
      "Best model updated\n",
      "\n",
      "Iteration 2/2\n",
      "Configuration: batch size = 256, epochs = 200, n_d = 16, n_a = 16, steps = 5, n_independent = 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0  | loss: 2.67814 | mse_mse: 1.13887 |  0:00:07s\n",
      "epoch 1  | loss: 0.35488 | mse_mse: 0.57869 |  0:00:14s\n",
      "epoch 2  | loss: 0.29018 | mse_mse: 0.33975 |  0:00:21s\n",
      "epoch 3  | loss: 0.26346 | mse_mse: 0.28686 |  0:00:29s\n",
      "epoch 4  | loss: 0.26972 | mse_mse: 0.27527 |  0:00:36s\n",
      "epoch 5  | loss: 0.25729 | mse_mse: 0.25326 |  0:00:44s\n",
      "epoch 6  | loss: 0.24918 | mse_mse: 0.32913 |  0:00:50s\n",
      "epoch 7  | loss: 0.25287 | mse_mse: 0.32665 |  0:00:58s\n",
      "epoch 8  | loss: 0.25665 | mse_mse: 0.24613 |  0:01:09s\n",
      "epoch 9  | loss: 0.24577 | mse_mse: 0.23293 |  0:01:17s\n",
      "epoch 10 | loss: 0.23597 | mse_mse: 0.22477 |  0:01:24s\n",
      "epoch 11 | loss: 0.23785 | mse_mse: 0.22116 |  0:01:31s\n",
      "epoch 12 | loss: 0.23973 | mse_mse: 0.2471  |  0:01:39s\n",
      "epoch 13 | loss: 0.23831 | mse_mse: 0.22552 |  0:01:46s\n",
      "epoch 14 | loss: 0.23231 | mse_mse: 0.2271  |  0:01:54s\n",
      "epoch 15 | loss: 0.23177 | mse_mse: 0.21862 |  0:02:00s\n",
      "epoch 16 | loss: 0.22228 | mse_mse: 0.20898 |  0:02:08s\n",
      "epoch 17 | loss: 0.23451 | mse_mse: 0.20807 |  0:02:15s\n",
      "epoch 18 | loss: 0.20739 | mse_mse: 0.19336 |  0:02:23s\n",
      "epoch 19 | loss: 0.19225 | mse_mse: 0.18261 |  0:02:30s\n",
      "epoch 20 | loss: 0.18126 | mse_mse: 0.16726 |  0:02:37s\n",
      "epoch 21 | loss: 0.1587  | mse_mse: 0.14276 |  0:02:44s\n",
      "epoch 22 | loss: 0.13588 | mse_mse: 0.13894 |  0:02:52s\n",
      "epoch 23 | loss: 0.12842 | mse_mse: 0.11007 |  0:02:59s\n",
      "epoch 24 | loss: 0.10675 | mse_mse: 0.0967  |  0:03:06s\n",
      "epoch 25 | loss: 0.11004 | mse_mse: 0.08705 |  0:03:14s\n",
      "epoch 26 | loss: 0.08939 | mse_mse: 0.07375 |  0:03:21s\n",
      "epoch 27 | loss: 0.07118 | mse_mse: 0.07047 |  0:03:29s\n",
      "epoch 28 | loss: 0.06358 | mse_mse: 0.0522  |  0:03:36s\n",
      "epoch 29 | loss: 0.0521  | mse_mse: 0.04552 |  0:03:43s\n",
      "epoch 30 | loss: 0.04974 | mse_mse: 0.05014 |  0:03:50s\n",
      "epoch 31 | loss: 0.04503 | mse_mse: 0.04035 |  0:03:58s\n",
      "epoch 32 | loss: 0.04396 | mse_mse: 0.04284 |  0:04:05s\n",
      "epoch 33 | loss: 0.03795 | mse_mse: 0.05406 |  0:04:13s\n",
      "epoch 34 | loss: 0.03617 | mse_mse: 0.0288  |  0:04:19s\n",
      "epoch 35 | loss: 0.03195 | mse_mse: 0.02932 |  0:04:28s\n",
      "epoch 36 | loss: 0.02931 | mse_mse: 0.02372 |  0:04:34s\n",
      "epoch 37 | loss: 0.02647 | mse_mse: 0.02329 |  0:04:42s\n",
      "epoch 38 | loss: 0.02785 | mse_mse: 0.02418 |  0:04:50s\n",
      "epoch 39 | loss: 0.02284 | mse_mse: 0.01846 |  0:04:57s\n",
      "epoch 40 | loss: 0.02511 | mse_mse: 0.02057 |  0:05:04s\n",
      "epoch 41 | loss: 0.02433 | mse_mse: 0.01712 |  0:05:12s\n",
      "epoch 42 | loss: 0.02423 | mse_mse: 0.03843 |  0:05:19s\n",
      "epoch 43 | loss: 0.02432 | mse_mse: 0.02192 |  0:05:26s\n",
      "epoch 44 | loss: 0.01905 | mse_mse: 0.01893 |  0:05:34s\n",
      "epoch 45 | loss: 0.022   | mse_mse: 0.01347 |  0:05:41s\n",
      "epoch 46 | loss: 0.01686 | mse_mse: 0.01252 |  0:05:49s\n",
      "epoch 47 | loss: 0.01635 | mse_mse: 0.01414 |  0:05:55s\n",
      "epoch 48 | loss: 0.01856 | mse_mse: 0.01967 |  0:06:03s\n",
      "epoch 49 | loss: 0.01857 | mse_mse: 0.01266 |  0:06:10s\n",
      "epoch 50 | loss: 0.01699 | mse_mse: 0.03236 |  0:06:18s\n",
      "epoch 51 | loss: 0.01721 | mse_mse: 0.01333 |  0:06:25s\n",
      "epoch 52 | loss: 0.01745 | mse_mse: 0.01372 |  0:06:33s\n",
      "epoch 53 | loss: 0.01429 | mse_mse: 0.01007 |  0:06:41s\n",
      "epoch 54 | loss: 0.01351 | mse_mse: 0.01274 |  0:06:48s\n",
      "epoch 55 | loss: 0.02196 | mse_mse: 0.01384 |  0:06:56s\n",
      "epoch 56 | loss: 0.02037 | mse_mse: 0.01688 |  0:07:03s\n",
      "epoch 57 | loss: 0.02494 | mse_mse: 0.01675 |  0:07:11s\n",
      "epoch 58 | loss: 0.02114 | mse_mse: 0.01677 |  0:07:18s\n",
      "epoch 59 | loss: 0.01678 | mse_mse: 0.01292 |  0:07:26s\n",
      "epoch 60 | loss: 0.01494 | mse_mse: 0.01663 |  0:07:33s\n",
      "epoch 61 | loss: 0.02048 | mse_mse: 0.01117 |  0:07:40s\n",
      "epoch 62 | loss: 0.01937 | mse_mse: 0.01662 |  0:07:48s\n",
      "epoch 63 | loss: 0.01877 | mse_mse: 0.01324 |  0:07:55s\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_mse_mse = 0.01007\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE: 0.010323455207568978\n",
      "R2 Score: 0.9534279012506903\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 打印最佳模型的详细信息\n",
    "print(\"Best Model:\", best_model)\n",
    "\n",
    "# 打印最佳模型的MSE\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# 如果之前没有计算过最佳模型的预测结果，则先进行预测\n",
    "# 这避免了重复进行相同的预测操作\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# 计算并打印最佳模型的R2分数\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "print(\"R2 Score:\", r2_best)"
   ],
   "metadata": {
    "id": "tl5_0wrKkAcT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706804300511,
     "user_tz": -60,
     "elapsed": 547,
     "user": {
      "displayName": "Zhiguang Li",
      "userId": "06031394133879865151"
     }
    },
    "outputId": "d515379d-27ff-4e7f-918d-62ad68ade9f3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Model: TabNetRegressor(n_d=16, n_a=16, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=[], n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=552, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1, grouped_features=[])\n",
      "Best MSE: 0.007878176810709618\n",
      "R2 Score: 0.9644592608757693\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 假设 best_model 是您训练好的 TabNet 模型\n",
    "# 保存模型\n",
    "#torch.save(best_model.state_dict(), 'best_model_tabnet.pth')\n",
    "\n",
    "#save the best model in a file csv\n",
    "best_model.save_model('best_model_tabnet_nopca_256.csv')"
   ],
   "metadata": {
    "id": "Y2SR8vikkB_6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706804300511,
     "user_tz": -60,
     "elapsed": 8,
     "user": {
      "displayName": "Zhiguang Li",
      "userId": "06031394133879865151"
     }
    },
    "outputId": "0365028b-7d7b-44df-c006-b3ca72f60a35"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully saved model at best_model_tabnet_nopca_256.csv.zip\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'best_model_tabnet_nopca_256.csv.zip'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  }
 ]
}
